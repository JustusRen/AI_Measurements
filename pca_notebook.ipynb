{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the class distribution of the utilized Fake/True News datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import squad_convert_examples_to_features\n",
    "from bnn import download_data, RANDOM_SEED\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import IncrementalPCA, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 3000\n",
    "COMPONENTS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('True.csv') and os.path.exists('Fake.csv'):\n",
    "    files = glob.glob('*.csv')\n",
    "else:\n",
    "    files = download_data()\n",
    "\n",
    "frames = {}\n",
    "for file in files:\n",
    "    frames[file] = pandas.read_csv(file, usecols=['text'])\n",
    "    if file == 'True.csv':\n",
    "        frames[file]['label'] = np.ones(frames[file].size)\n",
    "    else:\n",
    "        frames[file]['label'] = np.zeros(frames[file].size)\n",
    "\n",
    "dataset = pandas.concat(frames.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA: Plot for TF-IDF and BoW vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "analyzer = PCA(n_components=COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 12), dpi=100)\n",
    "for i in range(6):\n",
    "    # subset of the larger dataset to perform principle component analysis on\n",
    "    # (dataset is too large to process all at once)\n",
    "    subset = dataset.sample(n=SAMPLE_SIZE, random_state=RANDOM_SEED + i)\n",
    "\n",
    "    # split data and labels into x and y\n",
    "    x = subset['text'].values\n",
    "    y = subset['label'].values\n",
    "\n",
    "    # generate embeddings for TF-IDF\n",
    "    print(f'Iteration: {i + 1}')\n",
    "    tfidf_embeddings = tfidf_vectorizer.fit_transform(x).toarray()\n",
    "    print('TF-IDF matrix shape:', tfidf_embeddings.shape)\n",
    "\n",
    "    # principle component analysis of the tf-idf matrix/embeddings (keep 2 components and plot)\n",
    "    tfidf_pca = analyzer.fit_transform(tfidf_embeddings)\n",
    "    print('PCA matrix shape:', tfidf_pca.shape)\n",
    "\n",
    "    # plot data for this iteration\n",
    "    figure.add_subplot(2, 3, i + 1)\n",
    "    plt.scatter(tfidf_pca[y == 0, 0], tfidf_pca[y == 0, 1], color='b', s=10, label='False')\n",
    "    plt.scatter(tfidf_pca[y == 1, 0], tfidf_pca[y == 1, 1], color='r', s=10, label='True')\n",
    "    plt.title(f'PCA of TF-IDF Vectors (n={SAMPLE_SIZE}, iteration={i + 1})')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "figure = plt.figure(figsize=(16, 12), dpi=100)\n",
    "for i in range(6):\n",
    "    # subset of the larger dataset to perform principle component analysis on\n",
    "    # (dataset is too large to process all at once)\n",
    "    subset = dataset.sample(n=SAMPLE_SIZE, random_state=RANDOM_SEED + i)\n",
    "\n",
    "    # split data and labels into x and y\n",
    "    x = subset['text'].values\n",
    "    y = subset['label'].values\n",
    "\n",
    "    # generate embeddings for BOW\n",
    "    print(f'Iteration: {i + 1}')\n",
    "    bow_embeddings = bow_vectorizer.fit_transform(x).toarray()\n",
    "    print('BOW matrix shape:', bow_embeddings.shape)\n",
    "\n",
    "    # principle component analysis of the bow matrix/embeddings (keep 2 components and plot)\n",
    "    bow_pca = analyzer.fit_transform(bow_embeddings)\n",
    "    print('PCA matrix shape:', bow_pca.shape)\n",
    "\n",
    "    # plot data for this iteration\n",
    "    figure.add_subplot(2, 3, i + 1)\n",
    "    plt.scatter(bow_pca[y == 0, 0], bow_pca[y == 0, 1], color='b', s=10, label='False')\n",
    "    plt.scatter(bow_pca[y == 1, 0], bow_pca[y == 1, 1], color='r', s=10, label='True')\n",
    "    plt.title(f'PCA of BOW Vectors (n={SAMPLE_SIZE}, iteration={i + 1}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental PCA: Plot for TF-IDF and BoW vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "analyzer = IncrementalPCA(n_components=COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 12), dpi=100)\n",
    "for i in range(6):\n",
    "    # subset of the larger dataset to perform principle component analysis on\n",
    "    # (dataset is too large to process all at once)\n",
    "    subset = dataset.sample(n=SAMPLE_SIZE, random_state=RANDOM_SEED + i)\n",
    "\n",
    "    # split data and labels into x and y\n",
    "    x = subset['text'].values\n",
    "    y = subset['label'].values\n",
    "\n",
    "    # generate embeddings for TF-IDF\n",
    "    print(f'Iteration: {i + 1}')\n",
    "    tfidf_embeddings = tfidf_vectorizer.fit_transform(x).toarray()\n",
    "    print('TF-IDF matrix shape:', tfidf_embeddings.shape)\n",
    "\n",
    "    # principle component analysis of the tf-idf matrix/embeddings (keep 2 components and plot)\n",
    "    tfidf_pca = analyzer.fit_transform(tfidf_embeddings)\n",
    "    print('Inc. PCA matrix shape:', tfidf_pca.shape)\n",
    "\n",
    "    # plot data for this iteration\n",
    "    figure.add_subplot(2, 3, i + 1)\n",
    "    plt.scatter(tfidf_pca[y == 0, 0], tfidf_pca[y == 0, 1], color='b', s=10, label='False')\n",
    "    plt.scatter(tfidf_pca[y == 1, 0], tfidf_pca[y == 1, 1], color='r', s=10, label='True')\n",
    "    plt.title(f'Inc. PCA of TF-IDF Vectors (n={SAMPLE_SIZE}, iteration={i + 1})')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "figure = plt.figure(figsize=(16, 12), dpi=100)\n",
    "for i in range(6):\n",
    "    # subset of the larger dataset to perform principle component analysis on\n",
    "    # (dataset is too large to process all at once)\n",
    "    subset = dataset.sample(n=SAMPLE_SIZE, random_state=RANDOM_SEED + i)\n",
    "\n",
    "    # split data and labels into x and y\n",
    "    x = subset['text'].values\n",
    "    y = subset['label'].values\n",
    "\n",
    "    # generate embeddings for BOW\n",
    "    print(f'Iteration: {i + 1}')\n",
    "    bow_embeddings = bow_vectorizer.fit_transform(x).toarray()\n",
    "    print('BOW matrix shape:', bow_embeddings.shape)\n",
    "\n",
    "    # principle component analysis of the bow matrix/embeddings (keep 2 components and plot)\n",
    "    bow_pca = analyzer.fit_transform(bow_embeddings)\n",
    "    print('Inc. PCA matrix shape:', bow_pca.shape)\n",
    "\n",
    "    # plot data for this iteration\n",
    "    figure.add_subplot(2, 3, i + 1)\n",
    "    plt.scatter(bow_pca[y == 0, 0], bow_pca[y == 0, 1], color='b', s=10, label='False')\n",
    "    plt.scatter(bow_pca[y == 1, 0], bow_pca[y == 1, 1], color='r', s=10, label='True')\n",
    "    plt.title(f'Inc. PCA of BOW Vectors (n={SAMPLE_SIZE}, iteration={i + 1}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0250550d6d548e4e5a6cdc83ec66018a6064bd14f2654c3f43a648b49f3a281d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
