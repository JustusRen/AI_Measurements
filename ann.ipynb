{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "from common import *\n",
    "# import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data.csv'):\n",
    "    if not os.path.exists('Fake.csv') and not os.path.exists('True.csv'):\n",
    "        download_data()\n",
    "    label_data('Fake.csv', 'fake_labeled.csv', 1)\n",
    "    label_data('True.csv', 'true_labeled.csv', 0)\n",
    "    os.system(\"awk '(NR == 1) || (FNR > 1)' *labeled.csv > data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>Donald Trump is calling for one of the most co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31727</th>\n",
       "      <td>WASHINGTON (Reuters) - Former Republican U.S. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>You re never to young to commit jihad Teachers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13470</th>\n",
       "      <td>Laura Ingraham reminds the Never Trump people ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40814</th>\n",
       "      <td>BERLIN/HANOVER (Reuters) - Germany s Social De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "4528   Donald Trump is calling for one of the most co...      1\n",
       "31727  WASHINGTON (Reuters) - Former Republican U.S. ...      0\n",
       "10937  You re never to young to commit jihad Teachers...      1\n",
       "13470  Laura Ingraham reminds the Never Trump people ...      1\n",
       "40814  BERLIN/HANOVER (Reuters) - Germany s Social De...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', usecols=['text', 'label'], encoding='utf-8')\n",
    "df = df.sample(n=NUM_SAMPLES, random_state=RANDOM_SEED)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1500, 49912)\n",
      "Test shape: (1500, 49912)\n"
     ]
    }
   ],
   "source": [
    "countVectorizer = CountVectorizer()\n",
    "embeddings = preprocess_data(df['text'], countVectorizer)\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts= train_test_split(embeddings, df['label'], test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "X_tr = X_tr.toarray()\n",
    "X_ts = X_ts.toarray()\n",
    "\n",
    "feature_size = X_tr.shape[1]\n",
    "\n",
    "print(f'Train shape: {X_tr.shape}')\n",
    "print(f'Test shape: {X_ts.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:22:09.156060: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-20 14:22:09.156298: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                499130    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 499,141\n",
      "Trainable params: 499,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:22:11.416511: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-20 14:22:11.416542: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-20 14:22:11.416565: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n",
      "2022-04-20 14:22:11.416856: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#first basic ann\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "input_dim = X_tr.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:22:16.855351: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 598944000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.2457 - accuracy: 0.9382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:22:19.846404: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 598944000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 3s 19ms/step - loss: 0.2434 - accuracy: 0.9373 - val_loss: 0.1518 - val_accuracy: 0.9687\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0497 - accuracy: 0.9993 - val_loss: 0.1337 - val_accuracy: 0.9727\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9720\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9713\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9720\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9707\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9713\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9713\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9713\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9707\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9707\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9700\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9700\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9707\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9707\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9700\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9707\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9700\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9707\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9707\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 8.9463e-04 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9707\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 7.9020e-04 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9707\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 6.9978e-04 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9707\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 6.2128e-04 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9707\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 5.5283e-04 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9707\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 4.9313e-04 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9707\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 4.4050e-04 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9707\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.9474e-04 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9707\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.5368e-04 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9693\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.1768e-04 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9687\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.8642e-04 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9693\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 2.5770e-04 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9693\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 2.3246e-04 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9693\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 2.1015e-04 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9693\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 1.8975e-04 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9687\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 1.7195e-04 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9687\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 1.5548e-04 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9680\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 1.4095e-04 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9680\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 1.2809e-04 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9680\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.1616e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9680\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 1.0568e-04 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9687\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 9.6051e-05 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9680\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 8.7298e-05 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9673\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 7.9538e-05 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9673\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 7.2470e-05 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9673\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 6.6041e-05 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9673\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 6.0259e-05 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9673\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 5.4989e-05 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9667\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 5.0243e-05 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9673\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 4.5884e-05 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9673\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 4.1913e-05 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.8276e-05 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9673\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.4988e-05 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9667\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.2031e-05 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.9298e-05 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9667\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.6829e-05 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9667\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.4549e-05 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9673\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.2524e-05 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9653\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.0627e-05 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9653\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 1.8893e-05 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9660\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 1.7316e-05 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9647\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.5886e-05 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9653\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.4561e-05 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 1.3356e-05 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 1.2258e-05 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9640\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 1.1243e-05 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9640\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.0336e-05 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9633\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 9.4726e-06 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9627\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 8.7014e-06 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9627\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 7.9937e-06 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9627\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 7.3370e-06 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 0.9627\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 6.7447e-06 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9627\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 6.1920e-06 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9633\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 5.6875e-06 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9633\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 5.2328e-06 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9633\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 4.8123e-06 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.9627\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 4.4203e-06 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.9627\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 4.0675e-06 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9627\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.7396e-06 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9627\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.4338e-06 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9627\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 3.1597e-06 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9627\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.9043e-06 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9627\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 2.6714e-06 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.9620\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.4599e-06 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9620\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.2632e-06 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9620\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 2.0828e-06 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9620\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.9169e-06 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9620\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.7660e-06 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9613\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.6272e-06 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.9613\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.4967e-06 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.9613\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.3778e-06 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9600\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.2701e-06 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.9600\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 1.1684e-06 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9600\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 1.0763e-06 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9593\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 9.9192e-07 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9593\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 9.1384e-07 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9600\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 8.4175e-07 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9600\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 7.7568e-07 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.9600\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 7.1554e-07 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9600\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 6.5949e-07 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_tr, y_tr,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=True,\n",
    "    validation_data=(X_ts, y_ts),\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:26:03.058681: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 598944000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:26:05.645248: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 598944000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.9600\n"
     ]
    }
   ],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()\n",
    "\n",
    "loss, accuracy = model.evaluate(X_tr, y_tr, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_ts, y_ts, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_tr, y_ts= train_test_split(df['text'], df['label'], test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "print(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "X_tr = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_ts = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_tr = pad_sequences(X_tr, padding='post', maxlen=maxlen)\n",
    "X_ts = pad_sequences(X_ts, padding='post', maxlen=maxlen)\n",
    "\n",
    "print(X_tr[0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model_cnn.add(layers.GlobalMaxPool1D())\n",
    "model_cnn.add(layers.Dense(10, activation='relu'))\n",
    "model_cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_cnn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.fit(X_tr, y_tr, validation_data=(X_ts, y_ts), epochs=EPOCHS, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model_cnn.evaluate(X_tr, y_tr, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_cnn.evaluate(X_ts, y_ts, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "from typing import *\n",
    "# from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior and posterior likelihoods modeled by a zero-mean, unit-variance Gaussian normal distribution and multivariate Gaussian distribution with learnable mean and variances, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero mean, unit variance multivariate normal\n",
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "        n = kernel_size + bias_size\n",
    "        prior_model = keras.Sequential(\n",
    "            [\n",
    "                tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfp.distributions.MultivariateNormalDiag(\n",
    "                        loc=tf.zeros(n), scale_diag=tf.ones(n)\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        return prior_model\n",
    "\n",
    "# variational multivariate normal (learnable means and variances)\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.VariableLayer(\n",
    "                tfp.layers.MultivariateNormalTriL.params_size(n),\n",
    "                dtype=dtype\n",
    "            ),\n",
    "            tfp.layers.MultivariateNormalTriL(n)\n",
    "        ]\n",
    "    )\n",
    "    return posterior_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and compile model. The code below creates a hybrid BNN with 2 8-unit deterministic layers and a 2-unit probabilistic layer. The output is a normal distribution based on the parameters learned in the posterior functions/distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/avandebrook/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:26:19.421668: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(\n",
    "    shape=(feature_size,), dtype=tf.float64\n",
    ")\n",
    "\n",
    "features = keras.layers.BatchNormalization()(inputs)\n",
    "features = keras.layers.Dense(8, activation='sigmoid')(features)\n",
    "features = keras.layers.Dense(8, activation='sigmoid')(features)\n",
    "\n",
    "distribution_params = tfp.layers.DenseVariational(\n",
    "    units=2,\n",
    "    make_prior_fn=prior,\n",
    "    make_posterior_fn=posterior,\n",
    "    kl_weight=1/TRAIN_SIZE\n",
    ")(features)\n",
    "\n",
    "outputs = tfp.layers.IndependentNormal(1)(distribution_params)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate the model on the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:26:22.553670: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 598944000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 5s 70ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 9.2589e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 8.3295e-04 - categorical_accuracy: 1.0000 - val_loss: 8.6331e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 2s 45ms/step - loss: 8.9026e-04 - categorical_accuracy: 1.0000 - val_loss: 8.5515e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 9.0995e-04 - categorical_accuracy: 1.0000 - val_loss: 7.0427e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 2s 45ms/step - loss: 8.0133e-04 - categorical_accuracy: 1.0000 - val_loss: 6.6651e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 6.7251e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4418e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 6.6692e-04 - categorical_accuracy: 1.0000 - val_loss: 4.3222e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 4.5841e-04 - categorical_accuracy: 1.0000 - val_loss: 5.7999e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 3.6306e-04 - categorical_accuracy: 1.0000 - val_loss: 7.0538e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 6.0418e-04 - categorical_accuracy: 1.0000 - val_loss: 2.6314e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 2s 45ms/step - loss: 4.9068e-04 - categorical_accuracy: 1.0000 - val_loss: 4.5964e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 4.1952e-04 - categorical_accuracy: 1.0000 - val_loss: 4.7570e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 2s 45ms/step - loss: 2.2744e-04 - categorical_accuracy: 1.0000 - val_loss: 3.0247e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 2s 45ms/step - loss: 2.5261e-04 - categorical_accuracy: 1.0000 - val_loss: 3.2444e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.9326e-04 - categorical_accuracy: 1.0000 - val_loss: 1.8629e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 2.5141e-04 - categorical_accuracy: 1.0000 - val_loss: 1.5183e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 2.0792e-04 - categorical_accuracy: 1.0000 - val_loss: 1.2595e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.1913e-04 - categorical_accuracy: 1.0000 - val_loss: 1.7999e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 8.7121e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4438e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 1.6808e-04 - categorical_accuracy: 1.0000 - val_loss: 7.4602e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.1481e-04 - categorical_accuracy: 1.0000 - val_loss: 4.3284e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 7.8157e-05 - categorical_accuracy: 1.0000 - val_loss: 1.2199e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 9.6336e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4261e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 8.1886e-05 - categorical_accuracy: 1.0000 - val_loss: 1.0836e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 8.1324e-05 - categorical_accuracy: 1.0000 - val_loss: 6.4358e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 5.7040e-05 - categorical_accuracy: 1.0000 - val_loss: 9.9699e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 2.1212e-05 - categorical_accuracy: 1.0000 - val_loss: 3.5133e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 7.6626e-05 - categorical_accuracy: 1.0000 - val_loss: 3.3505e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 3.9781e-05 - categorical_accuracy: 1.0000 - val_loss: 1.8127e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.3172e-04 - categorical_accuracy: 1.0000 - val_loss: 2.7624e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 2.5127e-05 - categorical_accuracy: 1.0000 - val_loss: 6.4557e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 2s 43ms/step - loss: 5.5355e-05 - categorical_accuracy: 1.0000 - val_loss: 4.9440e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 2s 41ms/step - loss: 1.0653e-05 - categorical_accuracy: 1.0000 - val_loss: 6.9351e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 3s 58ms/step - loss: 7.8207e-05 - categorical_accuracy: 1.0000 - val_loss: 4.4535e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 3s 60ms/step - loss: 3.4623e-05 - categorical_accuracy: 1.0000 - val_loss: 8.7905e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 2.8774e-05 - categorical_accuracy: 1.0000 - val_loss: 1.9055e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: -1.8891e-05 - categorical_accuracy: 1.0000 - val_loss: -9.2919e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 3.9482e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1966e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 7.0009e-05 - categorical_accuracy: 1.0000 - val_loss: 7.5964e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 4.5078e-05 - categorical_accuracy: 1.0000 - val_loss: 6.1993e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 7.7013e-06 - categorical_accuracy: 1.0000 - val_loss: 7.8578e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 8.1972e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1054e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: -2.1700e-05 - categorical_accuracy: 1.0000 - val_loss: 2.7104e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 3.2870e-05 - categorical_accuracy: 1.0000 - val_loss: 6.5451e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.1437e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1414e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.1959e-06 - categorical_accuracy: 1.0000 - val_loss: 8.8797e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 7.3145e-05 - categorical_accuracy: 1.0000 - val_loss: 1.9347e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 7.4949e-05 - categorical_accuracy: 1.0000 - val_loss: -3.8635e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 3.1175e-05 - categorical_accuracy: 1.0000 - val_loss: 2.3623e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.9064e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0109e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: -1.0000e-05 - categorical_accuracy: 1.0000 - val_loss: 3.8283e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 4.8097e-05 - categorical_accuracy: 1.0000 - val_loss: 8.2946e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 1.6878e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1738e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 3.6437e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1681e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: -3.4706e-06 - categorical_accuracy: 1.0000 - val_loss: -4.1188e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 7.7035e-05 - categorical_accuracy: 1.0000 - val_loss: 1.0725e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 8.5936e-05 - categorical_accuracy: 1.0000 - val_loss: 6.6674e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 5.0603e-05 - categorical_accuracy: 1.0000 - val_loss: 3.2124e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 1.1025e-04 - categorical_accuracy: 1.0000 - val_loss: 1.2294e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 5.2352e-05 - categorical_accuracy: 1.0000 - val_loss: 1.2869e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 3.9688e-05 - categorical_accuracy: 1.0000 - val_loss: 9.1256e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 6.1241e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1524e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: -1.2273e-05 - categorical_accuracy: 1.0000 - val_loss: 3.3165e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 8.4916e-05 - categorical_accuracy: 1.0000 - val_loss: 3.1678e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.0660e-04 - categorical_accuracy: 1.0000 - val_loss: 1.6634e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: -5.8607e-05 - categorical_accuracy: 1.0000 - val_loss: 4.5269e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 5.6794e-05 - categorical_accuracy: 1.0000 - val_loss: 7.4529e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.6465e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6841e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 7.3287e-05 - categorical_accuracy: 1.0000 - val_loss: 3.7666e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 1.0674e-04 - categorical_accuracy: 1.0000 - val_loss: 5.9915e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 2.6903e-05 - categorical_accuracy: 1.0000 - val_loss: -2.7158e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: -9.9907e-06 - categorical_accuracy: 1.0000 - val_loss: 8.4526e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 7.3118e-05 - categorical_accuracy: 1.0000 - val_loss: 2.1460e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 8.8019e-06 - categorical_accuracy: 1.0000 - val_loss: 1.0312e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 6.3701e-06 - categorical_accuracy: 1.0000 - val_loss: 6.6827e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 7.8821e-05 - categorical_accuracy: 1.0000 - val_loss: -2.9598e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 4.7236e-05 - categorical_accuracy: 1.0000 - val_loss: 2.1225e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 1.0060e-04 - categorical_accuracy: 1.0000 - val_loss: 9.8113e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 9.3279e-06 - categorical_accuracy: 1.0000 - val_loss: 9.3867e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 8.0243e-05 - categorical_accuracy: 1.0000 - val_loss: 7.9653e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 1.0994e-04 - categorical_accuracy: 1.0000 - val_loss: 8.5951e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 9.4427e-05 - categorical_accuracy: 1.0000 - val_loss: 8.3961e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 1.2111e-04 - categorical_accuracy: 1.0000 - val_loss: 3.3740e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 1.1559e-04 - categorical_accuracy: 1.0000 - val_loss: 1.2193e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 1.0080e-04 - categorical_accuracy: 1.0000 - val_loss: -2.8438e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 3.9514e-05 - categorical_accuracy: 1.0000 - val_loss: 3.2750e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 5.7195e-05 - categorical_accuracy: 1.0000 - val_loss: 2.0663e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: -3.3708e-06 - categorical_accuracy: 1.0000 - val_loss: 1.1073e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 8.6373e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3223e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 8.6675e-05 - categorical_accuracy: 1.0000 - val_loss: 4.7512e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: -7.5542e-06 - categorical_accuracy: 1.0000 - val_loss: 8.7035e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 8.8363e-05 - categorical_accuracy: 1.0000 - val_loss: 1.0291e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 1.1736e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5568e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 9.4031e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1001e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 9.8495e-05 - categorical_accuracy: 1.0000 - val_loss: 1.0594e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 1.3692e-04 - categorical_accuracy: 1.0000 - val_loss: 1.1343e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 2.1186e-05 - categorical_accuracy: 1.0000 - val_loss: 1.0761e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 8.8178e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1270e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 4.1654e-06 - categorical_accuracy: 1.0000 - val_loss: 8.0767e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 2s 46ms/step - loss: 9.6568e-05 - categorical_accuracy: 1.0000 - val_loss: 5.3764e-05 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f17b373bcd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=tuple([X_ts, y_ts])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 24ms/step - loss: 8.7474e-05 - categorical_accuracy: 1.0000\n",
      "Training accuracy: 1.0\n",
      "47/47 [==============================] - 1s 15ms/step - loss: 1.0768e-04 - categorical_accuracy: 1.0000\n",
      "Testing accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "loss, accuracy = model.evaluate(X_tr, y_tr)\n",
    "print(f'Training accuracy: {accuracy}')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_ts, y_ts)\n",
    "print(f'Testing accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_ITERATIONS = 100\n",
    "\n",
    "results = pd.DataFrame(columns=['average', 'std', 'label'])\n",
    "\n",
    "# predict on test samples\n",
    "for i, sample in enumerate(X_ts):\n",
    "    sample = sample.reshape(1, sample.shape[0])\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(PREDICTION_ITERATIONS):\n",
    "        predictions.append(model.predict(sample))\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=1)\n",
    "    average = np.average(predictions, axis=1)\n",
    "    standard_deviation = np.std(predictions, axis=1)\n",
    "\n",
    "    frame = pd.DataFrame({'average': average, 'std': standard_deviation, 'label': y_ts.array[i]})\n",
    "    pd.concat([results, frame])\n",
    "\n",
    "    # print(\n",
    "    #     f'Sample: {i}\\n'\n",
    "    #     f'Average: {average[0]}\\n'\n",
    "    #     f'Standard Deviation: {standard_deviation[0]}\\n'\n",
    "    #     f'Label: {y_ts.array[i]}\\n\\n'\n",
    "    # )\n",
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0250550d6d548e4e5a6cdc83ec66018a6064bd14f2654c3f43a648b49f3a281d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
