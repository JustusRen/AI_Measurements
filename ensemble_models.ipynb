{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from common import *\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data.csv'):\n",
    "    if not os.path.exists('Fake.csv') and not os.path.exists('True.csv'):\n",
    "        download_data()\n",
    "    label_data('Fake.csv', 'fake_labeled.csv', 1)\n",
    "    label_data('True.csv', 'true_labeled.csv', 0)\n",
    "    os.system(\"awk '(NR == 1) || (FNR > 1)' *labeled.csv > data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>Donald Trump is calling for one of the most co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31727</th>\n",
       "      <td>WASHINGTON (Reuters) - Former Republican U.S. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>You re never to young to commit jihad Teachers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13470</th>\n",
       "      <td>Laura Ingraham reminds the Never Trump people ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40814</th>\n",
       "      <td>BERLIN/HANOVER (Reuters) - Germany s Social De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "4528   Donald Trump is calling for one of the most co...      1\n",
       "31727  WASHINGTON (Reuters) - Former Republican U.S. ...      0\n",
       "10937  You re never to young to commit jihad Teachers...      1\n",
       "13470  Laura Ingraham reminds the Never Trump people ...      1\n",
       "40814  BERLIN/HANOVER (Reuters) - Germany s Social De...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', usecols=['text', 'label'], encoding='utf-8')\n",
    "df = df.sample(n=NUM_SAMPLES, random_state=RANDOM_SEED)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_tr, y_tr, X_ts, y_ts, models):\n",
    "    for model in models:\n",
    "        score = cross_val_score(model, X_tr, y_tr, cv=5)\n",
    "        msg = (\"{0}:\\n\\tMean accuracy on development set\\t= {1:.3f} \"\n",
    "            \"(+/- {2:.3f})\".format(model.__class__.__name__,\n",
    "                                    score.mean(),\n",
    "                                    score.std()))\n",
    "        print(msg)\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred_eval = model.predict(X_ts)\n",
    "        acc_eval = accuracy_score(y_ts, pred_eval)\n",
    "        print(\"\\tAccuracy on evaluation set\\t\\t= {0:.3f}\".format(acc_eval))\n",
    "        print(\"Probability: \")\n",
    "        proba = model.predict_proba(X_ts)\n",
    "        print(proba)\n",
    "        print(classification_report(y_ts, pred_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_models = [ RandomForestClassifier(random_state=1),\n",
    "                    GradientBoostingClassifier(random_state=1),\n",
    "                    AdaBoostClassifier(random_state=1)  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1500, 49912)\n",
      "Test shape: (1500, 49912)\n"
     ]
    }
   ],
   "source": [
    "countVectorizer = CountVectorizer()\n",
    "embeddings_countVectorizer = preprocess_data(df['text'], countVectorizer)\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts= train_test_split(embeddings_countVectorizer, df['label'], test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f'Train shape: {X_tr.shape}')\n",
    "print(f'Test shape: {X_ts.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier:\n",
      "\tMean accuracy on development set\t= 0.966 (+/- 0.012)\n",
      "\tAccuracy on evaluation set\t\t= 0.968\n",
      "Probability: \n",
      "[[0.45 0.55]\n",
      " [0.56 0.44]\n",
      " [0.38 0.62]\n",
      " ...\n",
      " [0.27 0.73]\n",
      " [0.25 0.75]\n",
      " [0.38 0.62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       718\n",
      "           1       0.98      0.96      0.97       782\n",
      "\n",
      "    accuracy                           0.97      1500\n",
      "   macro avg       0.97      0.97      0.97      1500\n",
      "weighted avg       0.97      0.97      0.97      1500\n",
      "\n",
      "GradientBoostingClassifier:\n",
      "\tMean accuracy on development set\t= 0.991 (+/- 0.006)\n",
      "\tAccuracy on evaluation set\t\t= 0.989\n",
      "Probability: \n",
      "[[0.00390776 0.99609224]\n",
      " [0.99657346 0.00342654]\n",
      " [0.00697744 0.99302256]\n",
      " ...\n",
      " [0.00390776 0.99609224]\n",
      " [0.00390776 0.99609224]\n",
      " [0.00506603 0.99493397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       718\n",
      "           1       1.00      0.98      0.99       782\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n",
      "AdaBoostClassifier:\n",
      "\tMean accuracy on development set\t= 0.993 (+/- 0.007)\n",
      "\tAccuracy on evaluation set\t\t= 0.989\n",
      "Probability: \n",
      "[[0.45690124 0.54309876]\n",
      " [0.62277597 0.37722403]\n",
      " [0.38203907 0.61796093]\n",
      " ...\n",
      " [0.4000665  0.5999335 ]\n",
      " [0.34488416 0.65511584]\n",
      " [0.36529267 0.63470733]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       718\n",
      "           1       0.99      0.98      0.99       782\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_models(X_tr, y_tr, X_ts, y_ts, ensamble_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1500, 49912)\n",
      "Test shape: (1500, 49912)\n"
     ]
    }
   ],
   "source": [
    "tfidfVectorizer = TfidfVectorizer()\n",
    "embeddings_Tfidf = preprocess_data(df['text'], tfidfVectorizer)\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts= train_test_split(embeddings_Tfidf, df['label'], test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f'Train shape: {X_tr.shape}')\n",
    "print(f'Test shape: {X_ts.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier:\n",
      "\tMean accuracy on development set\t= 0.966 (+/- 0.008)\n",
      "\tAccuracy on evaluation set\t\t= 0.967\n",
      "Probability: \n",
      "[[0.39 0.61]\n",
      " [0.54 0.46]\n",
      " [0.39 0.61]\n",
      " ...\n",
      " [0.25 0.75]\n",
      " [0.29 0.71]\n",
      " [0.37 0.63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       718\n",
      "           1       0.98      0.96      0.97       782\n",
      "\n",
      "    accuracy                           0.97      1500\n",
      "   macro avg       0.97      0.97      0.97      1500\n",
      "weighted avg       0.97      0.97      0.97      1500\n",
      "\n",
      "GradientBoostingClassifier:\n",
      "\tMean accuracy on development set\t= 0.993 (+/- 0.006)\n",
      "\tAccuracy on evaluation set\t\t= 0.990\n",
      "Probability: \n",
      "[[0.00342275 0.99657725]\n",
      " [0.99720467 0.00279533]\n",
      " [0.00547589 0.99452411]\n",
      " ...\n",
      " [0.00297852 0.99702148]\n",
      " [0.00297852 0.99702148]\n",
      " [0.0039143  0.9960857 ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       718\n",
      "           1       0.99      0.99      0.99       782\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n",
      "AdaBoostClassifier:\n",
      "\tMean accuracy on development set\t= 0.993 (+/- 0.006)\n",
      "\tAccuracy on evaluation set\t\t= 0.990\n",
      "Probability: \n",
      "[[0.45009817 0.54990183]\n",
      " [0.59920454 0.40079546]\n",
      " [0.42821681 0.57178319]\n",
      " ...\n",
      " [0.33582182 0.66417818]\n",
      " [0.2981463  0.7018537 ]\n",
      " [0.33340235 0.66659765]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       718\n",
      "           1       0.99      0.99      0.99       782\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_models(X_tr, y_tr, X_ts, y_ts, ensamble_models)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0250550d6d548e4e5a6cdc83ec66018a6064bd14f2654c3f43a648b49f3a281d"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
